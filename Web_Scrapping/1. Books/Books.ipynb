{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a62d1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests, openpyxl, time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8da0d12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping page 6...\n",
      "Scraping page 7...\n",
      "Scraping page 8...\n",
      "Scraping page 9...\n",
      "Scraping page 10...\n",
      "Scraping page 11...\n",
      "Scraping page 12...\n",
      "Scraping page 13...\n",
      "Scraping page 14...\n",
      "Scraping page 15...\n",
      "Scraping page 16...\n",
      "Scraping page 17...\n",
      "Scraping page 18...\n",
      "Scraping page 19...\n",
      "Scraping page 20...\n",
      "Scraping page 21...\n",
      "Scraping page 22...\n",
      "Scraping page 23...\n",
      "Scraping page 24...\n",
      "Scraping page 25...\n",
      "Scraping page 26...\n",
      "Scraping page 27...\n",
      "Scraping page 28...\n",
      "Scraping page 29...\n",
      "Scraping page 30...\n",
      "Scraping page 31...\n",
      "Scraping page 32...\n",
      "Scraping page 33...\n",
      "Scraping page 34...\n",
      "Scraping page 35...\n",
      "Scraping page 36...\n",
      "Scraping page 37...\n",
      "Scraping page 38...\n",
      "Scraping page 39...\n",
      "Scraping page 40...\n",
      "Scraping page 41...\n",
      "Scraping page 42...\n",
      "Scraping page 43...\n",
      "Scraping page 44...\n",
      "Scraping page 45...\n",
      "Scraping page 46...\n",
      "Scraping page 47...\n",
      "Scraping page 48...\n",
      "Scraping page 49...\n",
      "Scraping page 50...\n",
      "Scraping completed and data saved as 'All_Books.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Create Excel workbook and sheet\n",
    "excel = openpyxl.Workbook()\n",
    "sheet = excel.active\n",
    "sheet.title = \"Books\"\n",
    "sheet.append(['Title', 'Star Rating', 'Price', 'Availability'])\n",
    "\n",
    "base_url = \"https://books.toscrape.com/catalogue/page-{}.html\"\n",
    "\n",
    "try:\n",
    "    for page in range(1, 51):  # Loop through pages 1 to 50\n",
    "        print(f\"Scraping page {page}...\")\n",
    "\n",
    "        url = base_url.format(page)\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36\"\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        books = soup.find_all('article', class_='product_pod')\n",
    "\n",
    "        for book in books:\n",
    "            title = book.h3.a['title']\n",
    "            star_rating = book.p['class'][1]\n",
    "            price = book.find('p', class_='price_color').text.strip()\n",
    "            stock = book.find('p', class_='instock availability').text.strip()\n",
    "\n",
    "            sheet.append([title, star_rating, price, stock])\n",
    "\n",
    "        time.sleep(1)  # Be polite to the server (avoid too many rapid requests)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# Save Excel file\n",
    "excel.save('All_Books.xlsx')\n",
    "print(\"Scraping completed and data saved as 'All_Books.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8823027b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping genre: Travel\n",
      " - Page 1 of Travel\n",
      "Scraping genre: Mystery\n",
      " - Page 1 of Mystery\n",
      " - Page 2 of Mystery\n",
      " - Page 3 of Mystery\n",
      "Scraping genre: Historical Fiction\n",
      " - Page 1 of Historical Fiction\n",
      " - Page 2 of Historical Fiction\n",
      " - Page 3 of Historical Fiction\n",
      "Scraping genre: Sequential Art\n",
      " - Page 1 of Sequential Art\n",
      " - Page 2 of Sequential Art\n",
      " - Page 3 of Sequential Art\n",
      " - Page 4 of Sequential Art\n",
      " - Page 5 of Sequential Art\n",
      "Scraping genre: Classics\n",
      " - Page 1 of Classics\n",
      "Scraping genre: Philosophy\n",
      " - Page 1 of Philosophy\n",
      "Scraping genre: Romance\n",
      " - Page 1 of Romance\n",
      " - Page 2 of Romance\n",
      " - Page 3 of Romance\n",
      "Scraping genre: Womens Fiction\n",
      " - Page 1 of Womens Fiction\n",
      "Scraping genre: Fiction\n",
      " - Page 1 of Fiction\n",
      " - Page 2 of Fiction\n",
      " - Page 3 of Fiction\n",
      " - Page 4 of Fiction\n",
      " - Page 5 of Fiction\n",
      "Scraping genre: Childrens\n",
      " - Page 1 of Childrens\n",
      " - Page 2 of Childrens\n",
      " - Page 3 of Childrens\n",
      "Scraping genre: Religion\n",
      " - Page 1 of Religion\n",
      "Scraping genre: Nonfiction\n",
      " - Page 1 of Nonfiction\n",
      " - Page 2 of Nonfiction\n",
      " - Page 3 of Nonfiction\n",
      " - Page 4 of Nonfiction\n",
      " - Page 5 of Nonfiction\n",
      " - Page 6 of Nonfiction\n",
      " - Page 7 of Nonfiction\n",
      "Scraping genre: Music\n",
      " - Page 1 of Music\n",
      "Scraping genre: Default\n",
      " - Page 1 of Default\n",
      " - Page 2 of Default\n",
      " - Page 3 of Default\n",
      " - Page 4 of Default\n",
      " - Page 5 of Default\n",
      " - Page 6 of Default\n",
      " - Page 7 of Default\n",
      " - Page 8 of Default\n",
      " - Page 9 of Default\n",
      "Scraping genre: Science Fiction\n",
      " - Page 1 of Science Fiction\n",
      "Scraping genre: Sports and Games\n",
      " - Page 1 of Sports and Games\n",
      "Scraping genre: Add a comment\n",
      " - Page 1 of Add a comment\n",
      " - Page 2 of Add a comment\n",
      " - Page 3 of Add a comment\n",
      " - Page 4 of Add a comment\n",
      " - Page 5 of Add a comment\n",
      "Scraping genre: Fantasy\n",
      " - Page 1 of Fantasy\n",
      " - Page 2 of Fantasy\n",
      " - Page 3 of Fantasy\n",
      " - Page 4 of Fantasy\n",
      "Scraping genre: New Adult\n",
      " - Page 1 of New Adult\n",
      "Scraping genre: Young Adult\n",
      " - Page 1 of Young Adult\n",
      " - Page 2 of Young Adult\n",
      " - Page 3 of Young Adult\n",
      " - Page 4 of Young Adult\n",
      "Scraping genre: Science\n",
      " - Page 1 of Science\n",
      "Scraping genre: Poetry\n",
      " - Page 1 of Poetry\n",
      "Scraping genre: Paranormal\n",
      " - Page 1 of Paranormal\n",
      "Scraping genre: Art\n",
      " - Page 1 of Art\n",
      "Scraping genre: Psychology\n",
      " - Page 1 of Psychology\n",
      "Scraping genre: Autobiography\n",
      " - Page 1 of Autobiography\n",
      "Scraping genre: Parenting\n",
      " - Page 1 of Parenting\n",
      "Scraping genre: Adult Fiction\n",
      " - Page 1 of Adult Fiction\n",
      "Scraping genre: Humor\n",
      " - Page 1 of Humor\n",
      "Scraping genre: Horror\n",
      " - Page 1 of Horror\n",
      "Scraping genre: History\n",
      " - Page 1 of History\n",
      "Scraping genre: Food and Drink\n",
      " - Page 1 of Food and Drink\n",
      " - Page 2 of Food and Drink\n",
      " - Page 3 of Food and Drink\n",
      "Scraping genre: Christian Fiction\n",
      " - Page 1 of Christian Fiction\n",
      "Scraping genre: Business\n",
      " - Page 1 of Business\n",
      "Scraping genre: Biography\n",
      " - Page 1 of Biography\n",
      "Scraping genre: Thriller\n",
      " - Page 1 of Thriller\n",
      "Scraping genre: Contemporary\n",
      " - Page 1 of Contemporary\n",
      "Scraping genre: Spirituality\n",
      " - Page 1 of Spirituality\n",
      "Scraping genre: Academic\n",
      " - Page 1 of Academic\n",
      "Scraping genre: Self Help\n",
      " - Page 1 of Self Help\n",
      "Scraping genre: Historical\n",
      " - Page 1 of Historical\n",
      "Scraping genre: Christian\n",
      " - Page 1 of Christian\n",
      "Scraping genre: Suspense\n",
      " - Page 1 of Suspense\n",
      "Scraping genre: Short Stories\n",
      " - Page 1 of Short Stories\n",
      "Scraping genre: Novels\n",
      " - Page 1 of Novels\n",
      "Scraping genre: Health\n",
      " - Page 1 of Health\n",
      "Scraping genre: Politics\n",
      " - Page 1 of Politics\n",
      "Scraping genre: Cultural\n",
      " - Page 1 of Cultural\n",
      "Scraping genre: Erotica\n",
      " - Page 1 of Erotica\n",
      "Scraping genre: Crime\n",
      " - Page 1 of Crime\n",
      "Scraping completed and saved as 'Books_By_Genre.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Create Excel workbook\n",
    "excel = openpyxl.Workbook()\n",
    "sheet = excel.active\n",
    "sheet.title = \"Books by Genre\"\n",
    "sheet.append(['Genre', 'Title', 'Star Rating', 'Price', 'Availability'])\n",
    "\n",
    "base_url = \"https://books.toscrape.com/\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Step 1: Get all genre links\n",
    "    response = requests.get(base_url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    genre_list = soup.find('ul', class_='nav-list').find('ul').find_all('li')\n",
    "\n",
    "    for genre in genre_list:\n",
    "        genre_name = genre.a.text.strip()\n",
    "        genre_url = base_url + genre.a['href']\n",
    "\n",
    "        print(f\"Scraping genre: {genre_name}\")\n",
    "\n",
    "        page_num = 1\n",
    "        while True:\n",
    "            print(f\" - Page {page_num} of {genre_name}\")\n",
    "            paged_url = genre_url.replace('index.html', f'page-{page_num}.html')\n",
    "            \n",
    "            response = requests.get(paged_url, headers=headers)\n",
    "            \n",
    "            if response.status_code == 404:\n",
    "                # No more pages for this genre\n",
    "                break\n",
    "            \n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            books = soup.find_all('article', class_='product_pod')\n",
    "\n",
    "            for book in books:\n",
    "                title = book.h3.a['title']\n",
    "                star_rating = book.p['class'][1]\n",
    "                price = book.find('p', class_='price_color').text.strip()\n",
    "                stock = book.find('p', class_='instock availability').text.strip()\n",
    "\n",
    "                sheet.append([genre_name, title, star_rating, price, stock])\n",
    "\n",
    "            page_num += 1\n",
    "            time.sleep(1)  # Be polite to the server\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# Save the Excel file\n",
    "excel.save('Books_By_Genre.xlsx')\n",
    "print(\"Scraping completed and saved as 'Books_By_Genre.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fc09ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Title Star Rating   Price  \\\n",
      "0                                  A Light in the Attic       Three  £51.77   \n",
      "1                                    Tipping the Velvet         One  £53.74   \n",
      "2                                            Soumission         One  £50.10   \n",
      "3                                         Sharp Objects        Four  £47.82   \n",
      "4                 Sapiens: A Brief History of Humankind        Five  £54.23   \n",
      "...                                                 ...         ...     ...   \n",
      "1718  Mexican Today: New and Rediscovered Recipes fo...        Five  £24.91   \n",
      "1719  Vegan Vegetarian Omnivore: Dinner for Everyone...         Two  £13.66   \n",
      "1720                       The Smitten Kitchen Cookbook         One  £23.59   \n",
      "1721  The Art of Simple Food: Notes, Lessons, and Re...       Three  £34.32   \n",
      "1722  Hungry Girl Clean & Hungry: Easy All-Natural R...       Three  £33.14   \n",
      "\n",
      "     Availability           Genre  \n",
      "0        In stock             NaN  \n",
      "1        In stock             NaN  \n",
      "2        In stock             NaN  \n",
      "3        In stock             NaN  \n",
      "4        In stock             NaN  \n",
      "...           ...             ...  \n",
      "1718     In stock  Food and Drink  \n",
      "1719     In stock  Food and Drink  \n",
      "1720     In stock  Food and Drink  \n",
      "1721     In stock  Food and Drink  \n",
      "1722     In stock  Food and Drink  \n",
      "\n",
      "[1723 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "books1 = pd.read_excel('All_Books.xlsx')\n",
    "books2 = pd.read_excel('Books_By_Genre.xlsx')\n",
    "\n",
    "# Concatenate vertically (stack rows)\n",
    "combined_books = pd.concat([books1, books2], ignore_index=True)\n",
    "\n",
    "# Display result\n",
    "print(combined_books)\n",
    "\n",
    "# Optionally, save to a new CSV\n",
    "combined_books.to_excel('Books.xlsx', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
